\chapter{Diskussion und Ausblick}
\label{chap:diskussion}

Die vorhergehenden Kapitel haben die Konzeption, Implementierung und systematische Evaluation des entwickelten Prototyps zur automatisierten Datenextraktion aus Gleisplänen dokumentiert. Dieses abschließende Kapitel ordnet die erzielten Ergebnisse in den wissenschaftlichen Kontext ein, reflektiert die methodischen Entscheidungen kritisch und gibt einen Ausblick auf zukünftige Entwicklungsmöglichkeiten.

%==============================================================================
\section{Einordnung der Ergebnisse}
\label{sec:einordnung}
%==============================================================================

Die in Kapitel~\ref{chap:evaluation} präsentierten Evaluationsergebnisse ermöglichen eine fundierte Bewertung des entwickelten Systems. Die End-to-End-Genauigkeit von 97,22\% auf dem Testsatz übertrifft die in Kapitel~\ref{chap:anforderungen} definierte Anforderung \hyperref[req:NFA-003]{NFA-003} ($\geq$ 85\%) um 12,22 Prozentpunkte. Die Zeitersparnis von 89,7\% gegenüber dem manuellen Prozess validiert den praktischen Nutzen des Ansatzes.

\subsection{Erfüllung der Kernziele}

Hinsichtlich der Objekterkennung sind zwei Leistungsmetriken zu unterscheiden: Die \textbf{Trainingsleistung} des YOLOv8-OBB-Modells wird durch die mAP@0.5 von 98,4\% auf dem Validierungssatz (208 Tiles) quantifiziert und demonstriert die Effektivität der OBB-basierten Architektur. Die geforderte Rotationsinvarianz (\hyperref[req:FA-002]{FA-002}) wurde durch synthetische Augmentation erreicht: Der Datensatz wurde von 482 Original-Tiles auf 1.131 Tiles erweitert, wie in Abschnitt~\ref{subsec:Datensatzerstellung} beschrieben. Bemerkenswert ist dabei, dass steilrotierte Objekte mit Winkeln größer 30° höhere Konfidenzwerte aufweisen (0,946) als kardinal orientierte Objekte (0,890), was die Robustheit des Augmentationsansatzes belegt.

Die \textbf{Testleistung} auf neun vollständig unabhängigen Produktionsplänen bestätigt die Generalisierungsfähigkeit: Die YOLO-Komponente erreichte eine Detektionsrate von 99,93\% (1.472 von 1.473 Objekten erkannt), wobei lediglich ein einziger \textit{isolierstoß} in Plan 9 nicht detektiert wurde. Diese hohe Detektionszuverlässigkeit auf zuvor ungesehenen Daten ist für sicherheitskritische Anwendungen essentiell.

Die End-to-End-Pipeline extrahierte im Testsatz 1.432 von 1.473 Objekten vollständig korrekt. Die transparente Fehleranalyse in Tabelle~\ref{tab:error_source_analysis_test} zeigt die Verteilung: 27 OCR-Fehler (65,9\%), 13 Linking-Fehler (31,7\%) und lediglich 1 Detection-Fehler (2,4\%). Diese Zuordenbarkeit ermöglicht gezielte Optimierungen der jeweiligen Komponenten.

\subsection{Vergleich mit verwandten Arbeiten}

Im Kontext der in Kapitel~\ref{chap:theoretischeundtechnischegrundlagen} diskutierten Literatur positioniert sich diese Arbeit zwischen generischen Document-AI-Systemen und hochspezialisierten Domänenlösungen. Arbeiten zur P\&ID-Erkennung erreichen typischerweise Symbolerkennungsgenauigkeiten zwischen 91--94\%: Yu et al.~\cite{Yu2019} berichten 91,6\% Symbolerkennung, während Elyan et al.~\cite{Elyan2020} über 94\% mit YOLO-basierter Detektion erzielten. Die hier erreichten 97,5\% Precision und 95,7\% Recall übertreffen diese Werte, was auf die Kombination aus OBB-Architektur und synthetischer Rotationsaugmentation zurückzuführen ist.

Gegenüber generischen Modellen wie LayoutLMv3~\cite{huang2022layoutlmv3pretrainingdocumentai} demonstriert diese Arbeit, dass domänenspezifisches Training mit vergleichsweise kleinem Datensatz hohe Genauigkeit erzielen kann, ohne auf massive Vortrainings-Datensätze angewiesen zu sein.

%==============================================================================
\section{Kritische Reflexion}
\label{sec:kritische_reflexion}
%==============================================================================

Die erfolgreichen Evaluationsergebnisse sollen nicht darüber hinwegtäuschen, dass bei der Entwicklung bewusste methodische Entscheidungen getroffen wurden, deren Implikationen hier reflektiert werden.

\subsection{Methodische Überlegungen}

Der Trainingsdatensatz von 24 Originalplänen, erweitert auf 1.131 Tiles durch synthetische Augmentation, ist für eine Masterarbeit angemessen. Die erfolgreiche Evaluation auf separaten Produktionsplänen deutet auf gute Generalisierungsfähigkeit \textit{innerhalb des trainierten Layouts} hin. Die Übertragbarkeit auf fundamental unterschiedliche Layouts -- etwa andere Bahnbetreiber, historische Pläne oder internationale Normen -- wurde jedoch nicht evaluiert und würde Nachtraining erfordern.

Die gewählte modulare Pipeline-Struktur (YOLO → OCR → Linking → Validierung) bietet hohe Interpretierbarkeit, da Fehler eindeutig einer Komponente zugeordnet werden können. Dieser Vorteil wird jedoch durch die Möglichkeit von Fehlerpropagation zwischen Stufen erkauft: Ein fehlerhaft ermittelter Bounding-Box-Winkel aus der YOLO-Komponente führt zu falscher Textausrichtung in der OCR-Phase. Ein End-to-End trainierbares System könnte solche Kaskadenfehler vermeiden, würde jedoch die Datenanforderungen drastisch erhöhen und die Transparenz reduzieren.

Die Entscheidung für CPU-basierte Inferenz erfüllt die Anforderungen \hyperref[req:NFA-001]{NFA-001} (On-Premise) und \hyperref[req:NFA-007]{NFA-007} (Standard-Hardware), führt jedoch zu Verarbeitungszeiten von durchschnittlich 10,6 Minuten pro Plan. GPU-Beschleunigung könnte die YOLO-Inferenzzeit von 556 Sekunden auf geschätzt 50--100 Sekunden reduzieren, was in Abschnitt~\ref{sec:verbesserungen} als mittelfristige Erweiterungsmöglichkeit diskutiert wird.

\subsection{Nicht vollständig erreichte Aspekte}

Trotz der hohen Genauigkeit erfordert die verbleibende Fehlerrate von 2,78\% weiterhin menschliche Qualitätskontrolle. Bei durchschnittlich 164 Objekten pro Plan entspricht dies etwa 4--5 Korrekturen. Das System ist daher als \textit{Assistenzsystem} konzipiert, nicht als vollautomatische Lösung -- was für sicherheitskritische Anwendungen angemessen ist.

Der Prototyp ist zudem auf das Trainguard MT ZUB Layout spezialisiert. Die strikte 500-DPI-Anforderung und die Beschränkung auf 13 Symbolklassen bedeuten, dass eine Übertragung auf andere Layouts Nachtraining erfordert. Die modulare Architektur ermöglicht solche Anpassungen durch Austausch von Konfigurationsdateien und Modellgewichten, wie in Abschnitt~\ref{sec:generalisierung} erläutert.

%==============================================================================
\section{Identifizierte Limitationen}
\label{sec:limitationen}
%==============================================================================

Die systematische Evaluation hat neben den Stärken auch die Grenzen des entwickelten Systems aufgezeigt. Diese Limitationen lassen sich in drei Kategorien gliedern.

\textbf{Datenbezogene Limitationen.} Die Auflösungsabhängigkeit stellt eine wesentliche Einschränkung dar: Das Modell erfordert zwingend 500 DPI Eingabeauflösung. Tests mit niedrigeren Auflösungen zeigten erheblich reduzierte Erkennungsraten, da Symbole weniger Details aufweisen und OCR-Texte an Schärfe verlieren. Die Layout-Spezialisierung auf Siemens Trainguard MT ZUB bedeutet, dass Pläne anderer Bahnbetreiber oder Sicherungssysteme Nachtraining erfordern würden. Schließlich decken die 13 implementierten Symbolklassen zwar das Zielprojekt vollständig ab, weitere Bahnelemente wie LZB-Komponenten oder Bahnübergangstechnik wurden jedoch nicht trainiert.

\textbf{Technische Limitationen.} Trotz der Multi-Engine-Kaskadierung verbleiben systematische OCR-Fehler bei Extrembedingungen. Die O/0-Verwechslung verursachte 9 der 27 OCR-Fehler im Testsatz. Fehlende Zeichen traten bei Texthöhen unter 25 Pixel auf, und Nachbarrauschen durch benachbarte Elemente führte gelegentlich zu falschen Erkennungen.

Die Linking-Komponente zeigt Ambiguitäten in hochkomplexen Bereichen mit mehreren Koordinatenkandidaten in ähnlicher Distanz. Von den 13 Linking-Fehlern betrafen 8 falsche Koordinatenzuordnungen in solchen Mehrdeutigkeitssituationen. Zusätzlich verursachen Objekte an Tile-Grenzen vereinzelt Duplikate oder fehlerhafte Verknüpfungen, obwohl die 12,5\% Überlappung und Non-Maximum-Suppression die meisten Fälle abfangen.

\textbf{Prozessuale Limitationen.} Die Fehlerrate von 2,78\% (41 von 1.473 Objekten) erfordert menschliche Qualitätskontrolle. Die Validierungskomponente identifizierte alle Fehler korrekt, sodass nur die markierten Fälle geprüft werden müssen -- dennoch ist vollautomatischer Betrieb ohne Supervision nicht möglich.

Das System verfügt zudem über kein semantisches Verständnis der Planinhalte. Automatische Prüfungen von Kilometrierung-Monotonie, Signal-Duplikaten oder technischen Abhängigkeiten (z.B.\ dass jedes Hauptsignal eine zugeordnete GKS haben muss) sind nicht implementiert. Schließlich ist der Prototyp ein Standalone-Tool ohne Integration in CAD-Systeme oder Projektdatenbanken.

%==============================================================================
\section{Verbesserungspotenziale}
\label{sec:verbesserungen}
%==============================================================================

Basierend auf den identifizierten Limitationen und der detaillierten Fehleranalyse werden im Folgenden priorisierte Verbesserungsansätze vorgeschlagen. Die Priorisierung orientiert sich am Verhältnis von erwartetem Nutzen zu Implementierungsaufwand.

\subsection{Kurzfristige Optimierungen}

Für einen Zeithorizont von null bis sechs Monaten bieten sich Optimierungen an, die ohne grundlegende Architekturänderungen umsetzbar sind.

Im Bereich der OCR-Optimierung wären domänenspezifische Nachkorrekturen vielversprechend: Die automatische Konvertierung von O zu 0 in numerischen Kontexten sowie die Entfernung von Leerzeichen in Signalbezeichnungen könnten einen signifikanten Teil der häufigsten Fehlerquelle adressieren. Zusätzlich würde adaptives Upsampling für Textausschnitte mit einer Höhe unter 40 Pixel die Erkennungsraten bei kleinen Beschriftungen verbessern.

Die Linking-Komponente könnte durch konfidenzbasiertes Scoring verbessert werden: Bei gleicher Distanz sollte der Kandidat mit höherer OCR-Konfidenz bevorzugt werden. Die Integration von Topologie-Informationen aus den Gleisverläufen als zusätzliche Constraints wäre ebenfalls vielversprechend.

Erweiterte Validierungsregeln könnten semantische Plausibilitätsprüfungen implementieren: Prüfung auf konsistente Kilometrierung-Steigerung entlang eines Gleises, Warnung bei identischen Signalbezeichnungen und Markierung von Koordinaten außerhalb plausibler Wertebereiche.

Der erwartete Nutzen dieser kurzfristigen Maßnahmen wäre eine Steigerung der End-to-End-Genauigkeit von 97,22\% auf 99,0--99,5\%.

\subsection{Mittel- und langfristige Perspektiven}

Für einen Zeithorizont von sechs bis zwölf Monaten wären umfangreichere Erweiterungen denkbar. Ein neuronales Linking-Modell auf Basis von Graph Neural Networks könnte komplexere räumliche Zusammenhänge zwischen Symbolen und Texten lernen. Dies würde jedoch einen erweiterten Trainingsdatensatz von geschätzt 50--100 vollständig annotierten Plänen mit expliziten Relation-Labels erfordern.

GPU-Beschleunigung durch Batch-Inferenz könnte die Verarbeitungszeit von 10,6 Minuten auf unter 3 Minuten pro Plan reduzieren. Eine hybride Lösung mit automatischem CPU-Fallback wäre optimal für unterschiedliche Deployment-Szenarien.

Active Learning würde die systematische Erfassung von Korrekturen aus dem Produktiveinsatz ermöglichen und so inkrementelles Nachtraining mit realen Fehlerfällen erlauben.

\textbf{Langfristige Forschungsrichtungen.} Auf längere Sicht könnten multimodale End-to-End-Modelle, die Vision-Language-Architekturen nutzen, das direkte Lernen von Bild zu strukturiertem Output ermöglichen. Transfer Learning könnte die Übertragung auf andere Zeichnungsdomänen wie P\&ID-Diagramme oder Elektropläne erleichtern. Die Integration in digitale Zwillinge der Bahninfrastruktur würde die automatische Aktualisierung von 3D-Infrastrukturmodellen ermöglichen.

%==============================================================================
\section{Generalisierbarkeit}
\label{sec:generalisierung}
%==============================================================================

Die entwickelten Konzepte sind prinzipiell auf verwandte Domänen übertragbar. Die OBB-basierte Objekterkennung mit YOLOv8, die Multi-Engine OCR-Kaskadierung mit orientierungsadaptiver Verarbeitung, die modulare Pipeline-Architektur sowie die Tiling-Strategie für großformatige Dokumente repräsentieren etwa 60--70\% des Gesamtsystems und könnten direkt wiederverwendet werden.

Domänenspezifische Anpassungen wären für die verbleibenden 30--40\% erforderlich: Definition neuer Symbolklassen und Erstellung entsprechender Trainingsdaten, Anpassung der Linking-Heuristiken und Richtungspräferenzen, Entwicklung passender Regex-Validierungsmuster sowie gegebenenfalls andere Auflösungsanforderungen.

Für eine Übertragung auf P\&ID-Diagramme oder Elektropläne wäre ein geschätzter Aufwand von 2--4 Personenmonaten erforderlich -- wesentlich effizienter als eine Neuentwicklung.

%==============================================================================
\section{Ausblick}
\label{sec:ausblick}
%==============================================================================

Die erfolgreiche Evaluation hat zu Diskussionen über einen Piloteinsatz bei Siemens Mobility geführt. Ein möglicher Rollout würde zunächst den Einsatz in ausgewählten Projekten mit systematischer Erfassung von Fehlerfällen und User-Feedback umfassen. Die dabei gesammelten Daten könnten für Modell-Updates durch Nachtraining genutzt werden, bevor ein breiter Produktivbetrieb auf Standard-Workstations erfolgt.

Die modulare Architektur ermöglicht dabei den Austausch des YOLO-Modells auf neuere Versionen (YOLOv9, YOLOv10) mit geschätztem Aufwand von 2--4 Personentagen, da OCR-, Linking- und Validierungskomponenten unverändert bleiben würden.

Hinsichtlich technologischer Trends könnten Foundation Models für Document AI wie GPT-4 Vision oder Gemini zukünftig als Ergänzung dienen, etwa für Zero-Shot-Erkennung neuer Symboltypen oder natürlichsprachliche Abfragen über extrahierte Daten. Für sicherheitskritische Anwendungen mit hohen Genauigkeitsanforderungen und On-Premise-Betrieb bleibt der spezialisierte Ansatz dieser Arbeit jedoch vorteilhaft, da er vollständige Kontrolle über die Verarbeitung und deterministische Ergebnisse gewährleistet.

%==============================================================================
\section{Beantwortung der Forschungsfragen}
\label{sec:forschungsfragen_beantwortung}
%==============================================================================

Abschließend werden die in Kapitel~\ref{chap:einleitung} formulierten Forschungsfragen auf Basis der Evaluationsergebnisse beantwortet.

\subsection{Hauptforschungsfrage}

\textit{Wie lässt sich der Prozess der Datenextraktion aus heterogenen technischen Zeichnungen durch den Einsatz von Deep Learning und hybriden Verarbeitungsstrategien automatisieren?}

Die Automatisierung gelingt durch die Kombination dreier Kernkomponenten: Deep Learning für die Objekterkennung mittels YOLOv8-OBB (mAP@0.5: 98,4\%), eine hybride OCR-Strategie durch Multi-Engine-Kaskade mit 98,17\% impliziter Genauigkeit sowie regelbasiertes Linking mit lokaler Koordinatentransformation (99,12\% Verknüpfungsgenauigkeit). Die valide Überführung in strukturierte Datenmodelle wird durch den automatisierten Export in Excel-, CSV- und JSON-Formate gewährleistet (\hyperref[req:FA-009]{FA-009}, \hyperref[req:NFA-010]{NFA-010}). Die End-to-End-Genauigkeit von 97,22\% validiert die Machbarkeit dieses Ansatzes.

\subsection{Teilforschungsfragen}

Die erste Teilforschungsfrage adressierte die Eignung einstufiger Detektoren für rotierte Symbole. Die Evaluation zeigt, dass YOLOv8-OBB hervorragend geeignet ist, sofern geeignete Vorverarbeitungsstrategien implementiert werden: Tiling mit 2048×2048 Pixel bei 12,5\% Überlappung, hochauflösende Rasterisierung mit 500 DPI und synthetische Rotationsaugmentation mit zehn Winkeln. Die erreichten 97,5\% Precision und 95,7\% Recall übertreffen vergleichbare P\&ID-Arbeiten.

Die zweite Teilforschungsfrage betraf die Verknüpfung geometrischer und textueller Daten. Die Lösung basiert auf rotationsinvarianter Koordinatentransformation für lokale Richtungsdefinition, klassenspezifischen Suchbereichen und Regex-basierter Validierung. Mit 13 Linking-Fehlern bei 1.473 Objekten (0,88\% Fehlerrate) ist zuverlässige Zuordnung auch bei hoher Objektdichte möglich.

Die dritte Teilforschungsfrage zielte auf eine modulare Architektur. Die Pipeline-Struktur mit definierten Schnittstellen ermöglicht den komponentenweisen Austausch. Neue Symbolklassen erfordern lediglich YOLO-Nachtraining, Definition von Linking-Parametern und Hinzufügung von Regex-Mustern. Die erfolgreiche Integration aller 13 Klassen validiert dieses Design.

Die vierte Teilforschungsfrage betraf die Änderungserkennung. Der Vergleich strukturierter Extraktionsergebnisse mittels Hungarian-Algorithmus ermöglicht robuste Identifikation von hinzugefügten, gelöschten und verschobenen Elementen. Die Validierung anhand realer Planversionen bestätigt die Funktionsfähigkeit.

%==============================================================================
\section{Abschließende Bewertung}
\label{sec:abschliessend}
%==============================================================================

Diese Masterarbeit demonstriert die Machbarkeit einer automatisierten Datenextraktion aus technischen Gleisplänen mit hoher Genauigkeit. Der entwickelte Prototyp erreicht eine End-to-End-Genauigkeit von 97,22\% und eine Zeitersparnis von 89,7\% gegenüber dem manuellen Prozess.

Der zentrale technische Beitrag liegt in der erfolgreichen Kombination von OBB-basierter Objekterkennung, orientierungsadaptiver Multi-Engine-OCR und hybridem Symbol-Text-Linking. Die Rotationsinvarianz wurde durch synthetische Augmentation erreicht, wobei rotierte Objekte sogar höhere Konfidenzwerte erzielen als horizontal ausgerichtete.

Methodisch zeigt die Arbeit, dass domänenspezifisches Training mit begrenzten Daten -- 482 annotierte Tiles aus 24 Originalplänen -- durch gezielte Augmentation hohe Genauigkeit erzielen kann. Dies ist ein ermutigendes Ergebnis für industrielle Anwendungen, bei denen annotierte Trainingsdaten oft knapp sind.

Der praktische Beitrag besteht in einem funktionsfähigen Prototyp mit Benutzeroberfläche für realistische Human-in-the-Loop-Workflows. Die integrierten Validierungswerkzeuge reduzieren den Prüfaufwand auf die 2,78\% fehlerhaften Fälle, was den Einsatz als Assistenzsystem in sicherheitskritischen Anwendungen ermöglicht.

Die Limitationen -- Layout-Spezialisierung, 500-DPI-Anforderung, verbleibende Fehlerrate -- sind klar identifiziert und adressierbar. Die modulare Architektur gewährleistet Erweiterbarkeit und Wartbarkeit.

Zusammenfassend validiert diese Arbeit einen pragmatischen Hybrid-Ansatz zwischen datengetriebenen End-to-End-Modellen und regelbasierten Systemen. Dieser Mittelweg erreicht hohe Genauigkeit bei überschaubarem Datenaufwand und ist auf Standard-Hardware einsetzbar. Die erfolgreiche Evaluation auf realen Siemens Mobility Daten belegt das Potenzial, manuelle Prozesse signifikant zu beschleunigen und damit einen konkreten Beitrag zur Digitalisierung der Eisenbahninfrastruktur zu leisten.