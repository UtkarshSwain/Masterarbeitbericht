@Article{sym17050674,
AUTHOR = {Sun, Qi and Zhu, 
Mengxin and Li, 
Minzhi and Li, 
Gaoju and Deng, 
Weizhi},
TITLE = {Symbol Recognition Method for Railway Catenary Layout Drawings Based on Deep Learning},
JOURNAL = {Symmetry},
VOLUME = {17},
YEAR = {2025},
NUMBER = {5},
ARTICLE-NUMBER = {674},
URL = {https://www.mdpi.com/2073-8994/17/5/674},
ISSN = {2073-8994},
DOI = {10.3390/sym17050674}
}

@research-article{Ristic2023AutomatedDO,
title={Automated Development of Railway Signalling Control Tables: A Case Study from Serbia},
author={Ivan Ristic},
journal={Mechatronics and Intelligent Transportation Systems},
year={2023},
page={227-235},
doi={https://doi.org/10.56578/mits020404}
}
@book{VogelHeuser2017,
  title     = {Handbuch Industrie 4.0 Bd.2: Automatisierung},
  author    = {Vogel-Heuser, Birgit and Bauernhansl, Thomas and ten Hompel, Michael},
  year      = {2017},
  publisher = {Springer Vieweg},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-662-53249-6}
}
@InProceedings{Joshua,
author="Joshua, M.  Jesher
and Ragav, V.
and Ibrahim, S. P. Syed",
editor="Janmanee, Pichai
and Chujuarjeen, Saichol
and Butdee, Suthep
and Srikhumsuk, Phatchani
and Batako, Andre D. L.
and Burduk, Anna
and Xavior, M. Anthony",
title="Advanced Knowledge Extraction of Physical Design Drawings, Translation and Conversion to CAD Formats Using Deep Learning",
booktitle="Advanced in Creative Technology- added Value Innovations in Engineering, Materials and Manufacturing",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="343--356",
abstract="The maintenance, archiving and usage of the design drawings is cumbersome in physical form in different industries for longer period. It is hard to extract information by simple scanning of drawing sheets. Converting them to their digital formats such as Computer-Aided Design (CAD), with needed knowledge extraction can solve this problem. The conversion of these machine drawings to its digital form is a crucial challenge which requires advanced techniques. This research proposes an innovative methodology utilizing Deep Learning methods. The approach employs object detection model, such as Yolov7, Faster R-CNN, to detect physical drawing objects present in the images followed by, edge detection algorithms such as canny filter to extract and refine the identified lines from the drawing region and curve detection techniques to detect circle. Also ornaments (complex shapes) within the drawings are extracted. To ensure comprehensive conversion, an Optical Character Recognition (OCR) tool is integrated to identify and extract the text elements from the drawings. The extracted data which includes the lines, shapes and text is consolidated and stored in a structured comma separated values (csv) file format. The accuracy and the efficiency of conversion is evaluated. Through this, conversion can be automated to help organizations enhance their productivity, facilitate seamless collaborations and preserve valuable design information in a digital format easily accessible. Overall, this study contributes to the advancement of CAD conversions, providing accurate results from the translating process. Future research can focus on handling diverse drawing types, enhanced accuracy in shape and line detection and extraction.",
isbn="978-3-031-59164-8"
}

@software{yolov8_ultralytics,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@INPROCEEDINGS{10613721,
  author={Klinsrisuk, Chatbordin and Witayangkurn, Apichon},
  booktitle={2024 21st International Joint Conference on Computer Science and Software Engineering (JCSSE)}, 
  title={ASDR: Automatic System to Diagnose and Recognize Electrical Drawings}, 
  year={2024},
  volume={},
  number={},
  pages={118-125},
  keywords={YOLO;Training;Image segmentation;Accuracy;Substations;Engineering drawings;Transfer learning;Automated System;Metering and Relaying Diagram;Object Detection;YOLOv5;RTM-Det;Faster-RCNN;Machine Learning;Albumentations;Electrical Drawing},
  doi={10.1109/JCSSE61278.2024.10613721}
}


@article{railroadstationdrawing,
author = {Wang, Yuan and Li, Xiaopeng and Zhang, Yu},
title = {An automation solution to convert CAD engineering drawings into railroad station models},
journal = {Computer-Aided Civil and Infrastructure Engineering},
volume = {39},
number = {5},
pages = {679-691},
doi = {https://doi.org/10.1111/mice.13091},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.13091},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mice.13091},
abstract = {Abstract Creating a high-fidelity railroad station model to match the physical details of hundreds of tracks and switches is never a trivial task. The manual modeling approach often costs engineers significant efforts and constrains the generality and extensivity of many advanced methods. Taking advantage that many stations are drawn proportionally into two-dimensional drawing exchange format (DXF) files via state-of-the-art computer-aided design (CAD) techniques, this paper proposed an efficient solution to convert DXF files into meaningful station models. The proposed solution consists of two phases (1) converting graphic basic primitives without explicit engineering interpretations into recognizable railroad symbols and (2) modeling undirected railroad station graphs with necessary configurations such as endpoints and routes. The proposed solution is developed into a graphic user interface application with minimal user interactions and subsequently tested at several real-world passenger stations in Asia for its validity, productivity, and applicability.},
year = {2024}
}


@article{neuralnetwork,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}

@inproceedings{Ren2015_FasterRCNN,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 volume = {28},
 year = {2015}
}

@misc{YOLO,
author = {Hussain, Muhammad},
year = {2024},
month = {07},
pages = {},
title = {YOLOv5, YOLOv8 and YOLOv10: The Go-To Detectors for Real-time Vision},
doi = {10.48550/arXiv.2407.02988},
note = {arXiv:2407.02988} % Gut für arXiv-Preprints
}



@article{Jamieson2024,
author = {Jamieson, Laura and Moreno-García, Carlos and Elyan, Eyad},
year = {2024},
month = {05},
pages = {},
title = {A review of deep learning methods for digitisation of complex documents and engineering diagrams},
volume = {57},
journal = {Artificial Intelligence Review},
doi = {10.1007/s10462-024-10779-2}
}

@article{signallayout,
  author = {Luteberget, Bj\O{}rnar and Johansen, Christian},
  title = {Efficient verification of railway infrastructure designs against standard regulations},
  year = {2018},
  issue_date = {February  2018},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  volume = {52},
  number = {1},
  issn = {0925-9856},
  url = {https://doi.org/10.1007/s10703-017-0281-z},
  doi = {10.1007/s10703-017-0281-z},
  abstract = {In designing safety-critical infrastructures s.a. railway systems, engineers often have to deal with complex and large-scale designs. Formal methods can play an important role in helping automate various tasks. For railway designs formal methods have mainly been used to verify the safety of so-called interlockings through model checking, which deals with state change and rather complex properties, usually incurring considerable computational burden (e.g., the state-space explosion problem). In contrast, we focus on static infrastructure models, and are interested in checking requirements coming from design guidelines and regulations, as usually given by railway authorities or safety certification bodies. Our goal is to automate the tedious manual work that railway engineers do when ensuring compliance with regulations, through using software that is fast enough to do verification on-the-fly, thus being able to be included in the railway design tools, much like a compiler in an IDE. In consequence, this paper describes the integration into the railway design process of formal methods for automatically extracting railway models from the CAD railway designs and for describing relevant technical regulations and expert knowledge as properties to be checked on the models. We employ a variant of Datalog and use the standardized "railway markup language" railML as basis and exchange format for the formalization. We developed a prototype tool and integrated it in industrial railway CAD software, developed under the name RailCOMPLETE®. This on-the-fly verification tool is a help for the engineer while doing the designs, and is not a replacement to other more heavy-weight software like for doing interlocking verification or capacity analysis. Our tool, through the export into railML, can be easily integrated with these other tools. We apply our tool chain in a Norwegian railway project, the upgrade of the Arna railway station.},
  journal = {Form. Methods Syst. Des.},
  month = feb,
  pages = {1–32},
  numpages = {32},
  keywords = {Automation, CAD, Datalog, Incremental verification, Logic programming, Railway designs, Railway infrastructure, Signalling, railML}
}

@article{Adeli1986AMS,
  title={A MICROCAD system for design of steel connections—I. Program structure and graphic algorithms},
  author={Hojjat Adeli and James Fiedorek},
  journal={Computers \& Structures},
  year={1986},
  volume={24},
  pages={281-294},
  url={https://api.semanticscholar.org/CorpusID:111080620}
}

@mastersthesis{helle2023,
  author       = {Helle, Riku},
  title        = {Intelligent symbol attributes extraction from engineering drawings},
  school       = {University of Turku, Department of Computing},
  type         = {Master of Science (Tech) Thesis},
  year         = {2023},
  month        = jun,
  pages        = {69},
  address      = {Turku, Finland},
  note         = {Software Engineering},
  url          = {https://urn.fi/URN:NBN:fi-fe2023072691658},
  urldate      = {2023-06-29}
}

@book{szeliski2022,
  author    = {Szeliski, Richard},
  title     = {Computer Vision: Algorithms and Applications},
  series    = {Texts in Computer Science},
  edition   = {2},
  publisher = {Springer Cham},
  year      = {2022},
  doi       = {10.1007/978-3-030-34372-9},
  isbn      = {978-3-030-34371-2},
  pages     = {xxii+925},
  note      = {Also available as eBook: ISBN 978-3-030-34372-9},
  url       = {https://doi.org/10.1007/978-3-030-34372-9}
}


@article{Wang2022Classification,
  title={Classification of 3D CAD Models considering the Knowledge Recognition Algorithm of Convolutional Neural Network},
  author={Weiwei Wang and Dandan Sun},
  journal={Advances in Multimedia},
  year={2022},
  doi={10.1155/2022/1794571}
}

@article{Fedorov2023Railway,
  title={Railway Infrastructure Instance Segmentation Based on Convolutional Neural Networks},
  author={V. A. Fedorov},
  journal={2023 International Russian Automation Conference (RusAutoCon)},
  year={2023},
  pages={443-447},
  doi={10.1109/RusAutoCon58002.2023.10272908}
}


@misc{DINISO9001,
  title        = {{DIN EN ISO 9001:2015} Qualitätsmanagementsysteme -- Anforderungen},
  organization = {Deutsches Institut für Normung e. V. (DIN)},
  year         = {2015},
  note         = {ISO 9001:2015(E)},
}
@techreport{VDI1000,
  title        = {{VDI 1000:2017-06} VDI-Richtlinienarbeit -- Grundsätze und Anleitungen},
  institution  = {Verein Deutscher Ingenieure (VDI)},
  year         = {2017},
  type         = {VDI-Richtlinie},
}

@thesis{renuka2013change,
  author       = {Renuka, N.},
  title        = {Automation of Change Detection in Engineering Drawings},
  type         = {Master's Thesis},
  institution  = {Department of Electrical Engineering, Indian Institute of Technology Madras},
  year         = {2013},
  month        = may,
}

@article{Dohrn2014Finegrained,
  title={Fine-grained change detection in structured text documents},
  author={Hannes Dohrn and D. Riehle},
  year={2014},
  pages={87-96},
  doi={10.1145/2644866.2644880}
}

@INPROCEEDINGS{Smith2007,
  author={Smith, R.},
  booktitle={Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)}, 
  title={An Overview of the Tesseract OCR Engine}, 
  year={2007},
  volume={2},
  number={},
  pages={629-633},
  keywords={Optical character recognition software;Search engines;Testing;Open source software;Text recognition;Filters;Prototypes;Independent component analysis;Pipelines;Inspection},
  doi={10.1109/ICDAR.2007.4376991}
  }

@article{GRUBER1993199,
title = {A translation approach to portable ontology specifications},
journal = {Knowledge Acquisition},
volume = {5},
number = {2},
pages = {199-220},
year = {1993},
issn = {1042-8143},
doi = {https://doi.org/10.1006/knac.1993.1008},
url = {https://www.sciencedirect.com/science/article/pii/S1042814383710083},
author = {Thomas R. Gruber},
abstract = {To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse—definitions of classes, relations, functions, and other objects—is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.}
}

@article{STUDER1998161,
  author  = {Rudi Studer and V. Richard Benjamins and Dieter Fensel},
  title   = {Knowledge engineering: Principles and methods},
  journal = {Data \& Knowledge Engineering},
  volume  = {25},
  number  = {1},
  pages   = {161-197},
  year    = {1998},
  issn    = {0169-023X},
  doi     = {10.1016/S0169-023X(97)00056-6},
  url     = {https://www.sciencedirect.com/science/article/pii/S0169023X97000566}
}

@article{Uschold_Gruninger_1996, 
title={Ontologies: principles, methods and applications}, 
volume={11}, 
DOI={10.1017/S0269888900007797}, 
number={2}, 
journal={The Knowledge Engineering Review}, 
author={Uschold, Mike and Gruninger, Michael}, 
year={1996}, 
pages={93–136}
} 

@article{Gotel1994AnAO,
  title={An analysis of the requirements traceability problem},
  author={Olly Gotel and A. C. W. Finkelstein},
  journal={Proceedings of IEEE International Conference on Requirements Engineering},
  year={1994},
  pages={94-101},
  url={https://api.semanticscholar.org/CorpusID:5870868}
}

@book{book,
author = {Cleland-Huang, Jane and Zisman, A. and Gotel, O.},
year = {2012},
month = {10},
pages = {1-491},
title = {Software and Systems Traceability},
isbn = {978-1-4471-2238-8},
doi = {10.1007/978-1-4471-2239-5}
}

@book{10.5555/2821575,
author = {Nielsen, Jakob},
title = {Usability Engineering},
year = {1994},
isbn = {9780080520292},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Written by the author of the best-selling HyperText \& HyperMedia, this book is an excellent guide to the methods of usability engineering. The book provides the tools needed to avoid usability surprises and improve product quality. Step-by-step information on which method to use at various stages during the development lifecycle are included, along with detailed information on how to run a usability test and the unique issues relating to international usability. * Emphasizes cost-effective methods that developers can implement immediately * Instructs readers about which methods to use when, throughout the development lifecycle, which ultimately helps in cost-benefit analysis. * Shows readers how to avoid the four most frequently listed reasons for delay in software projects. * Includes detailed information on how to run a usability test. * Covers unique issues of international usability. * Features an extensive bibliography allowing readers to find additional information. * Written by an internationally renowned expert in the field and the author of the best-selling HyperText \& HyperMedia. Table of Contents Executive Summary. What is Usability Generations of User Interfaces. The Usability Engineering Lifecycle. Usability Heuristics. Usability Testing. Usability Assessment Methods Beyond Testing. Interface Standards. International User Interfaces. Future Developments. Appendix A: Exercises. Appendix B: Bibliography. Author Index. Subject Index.}
}

@inproceedings{NIPS2014_532a2f85,
 author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {How transferable are features in deep neural networks?},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/532a2f85b6977104bc93f8580abbb330-Paper.pdf},
 volume = {27},
 year = {2014}
 }

@ARTICLE{transferlearning,
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Transfer Learning}, 
  year={2010},
  volume={22},
  number={10},
  pages={1345-1359},
  keywords={Machine learning;Training data;Data mining;Knowledge transfer;Space technology;Knowledge engineering;Machine learning algorithms;Labeling;Learning systems;Testing;Transfer learning;survey;machine learning;data mining.},
  doi={10.1109/TKDE.2009.191}
  }

@article{dataugmentation,
  author = {Shorten, Connor and Khoshgoftaar, Taghi},
  year = {2019},
  month = {07},
  pages = {},
  title = {A survey on Image Data Augmentation for Deep Learning},
  volume = {6},
  journal = {Journal of Big Data},
  doi = {10.1186/s40537-019-0197-0}
  }

@misc{redmon2016lookonceunifiedrealtime,
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
  year={2016},
  eprint={1506.02640},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1506.02640}, 
}


@misc{yaseen2024yolov8indepthexplorationinternal,
      title={What is YOLOv8: An In-Depth Exploration of the Internal Features of the Next-Generation Object Detector}, 
      author={Muhammad Yaseen},
      year={2024},
      eprint={2408.15857},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.15857}, 
}

@misc{wang2024yolov9learningwantlearn,
      title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information}, 
      author={Chien-Yao Wang and I-Hau Yeh and Hong-Yuan Mark Liao},
      year={2024},
      eprint={2402.13616},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.13616}, 
}

@misc{wang2024yolov10realtimeendtoendobject,
      title={YOLOv10: Real-Time End-to-End Object Detection}, 
      author={Ao Wang and Hui Chen and Lihao Liu and Kai Chen and Zijia Lin and Jungong Han and Guiguang Ding},
      year={2024},
      eprint={2405.14458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.14458}, 
}

@inbook{Liu_2016,
   title={SSD: Single Shot MultiBox Detector},
   ISBN={9783319464480},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-319-46448-0_2},
   DOI={10.1007/978-3-319-46448-0_2},
   booktitle={Computer Vision – ECCV 2016},
   publisher={Springer International Publishing},
   author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
   year={2016},
   pages={21–37} 
}

@misc{lyu2022rtmdetempiricalstudydesigning,
      title={RTMDet: An Empirical Study of Designing Real-Time Object Detectors}, 
      author={Chengqi Lyu and Wenwei Zhang and Haian Huang and Yue Zhou and Yudong Wang and Yanyi Liu and Shilong Zhang and Kai Chen},
      year={2022},
      eprint={2212.07784},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.07784}, 
}
@mastersthesis{berg2011high,
  author       = {Øyvind Raddum Berg},
  title        = {High Precision Text Extraction from {PDF} Documents},
  school       = {University of Oslo, Department of Informatics},
  year         = {2011},
  month        = {4},
  type         = {Master's thesis},
  url          = {https://core.ac.uk/download/pdf/30827574.pdf}
}

@misc{schlagenhauf2022textdetectiontechnicaldrawings,
      title={Text Detection on Technical Drawings for the Digitization of Brown-field Processes}, 
      author={Tobias Schlagenhauf and Markus Netzer and Jan Hillinger},
      year={2022},
      eprint={2205.02659},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.02659}, 
}

@misc{paddleocr,
  author = {PaddlePaddle Team},
  howpublished = {\url{https://www.paddleocr.ai/latest/}},
  title = {Paddleocr: Multilingual, Lightweight, and Practical Optical Character Recognition},
  year = {2023},
  note = {Accessed: 2025-11-21},
}

@misc{khan2025drawingsdecisionshybridvisionlanguage,
      title={From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge}, 
      author={Muhammad Tayyab Khan and Lequn Chen and Zane Yong and Jun Ming Tan and Wenhe Feng and Seung Ki Moon},
      year={2025},
      eprint={2506.17374},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.17374}, 
}


@misc{KI-LOK2025,
  author       = {Leuschel, Michael and Gruteser, Jan and Roßbach, Jan},
  title        = {Prüfverfahren für KI-basierte Komponenten im Eisenbahnbetrieb (KI-LOK Abschlussbericht)},
  howpublished = {\url{https://docserv.uni-duesseldorf.de/servlets/DocumentServlet?id=67987}},
  note         = {URN: \url{urn:nbn:de:hbz:061-20250120-134832-2}},
  year         = {2025},
  language     = {German},
  keywords     = {Formale Methoden, Künstliche Intelligenz, Zugleitsysteme, Zertifizierung},
  abstract     = {Abschlussbericht des KI-LOK Forschungsprojekts. Im Projekt wurden Techniken für die Validierung und Verifikation KI-basierter Systeme der Bahntechnik sowie modellbasierte Methoden zum Test von autonomen Zugsystemen erforscht.},
  license      = {Creative Commons Namensnennung 4.0 International Lizenz},
}

@inproceedings{Vromans2005ReliabilityOR,
  title={Reliability of Railway Systems},
  author={Michiel J. C. M. Vromans},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:106807787}
}

@article{Patel,
author = {Patel, Chirag and Patel, Atul and Patel, Dharmendra},
year = {2012},
month = {10},
pages = {50-56},
title = {Optical Character Recognition by Open source OCR Tool Tesseract: A Case Study},
volume = {55},
journal = {International Journal of Computer Applications},
doi = {10.5120/8794-2784}
}

@misc{liao2019realtimescenetextdetection,
      title={Real-time Scene Text Detection with Differentiable Binarization}, 
      author={Minghui Liao and Zhaoyi Wan and Cong Yao and Kai Chen and Xiang Bai},
      year={2019},
      eprint={1911.08947},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1911.08947}, 
}

@misc{long2020scenetextdetectionrecognition,
      title={Scene Text Detection and Recognition: The Deep Learning Era}, 
      author={Shangbang Long and Xin He and Cong Yao},
      year={2020},
      eprint={1811.04256},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1811.04256}, 
}
@article{García,
author = {Moreno-García, Carlos and Elyan, Eyad and Jayne, Chrisina},
year = {2019},
month = {06},
pages = {},
title = {New trends on digitisation of complex engineering drawings},
volume = {31},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-018-3583-1}
}
@article{SAUVOLA2000225,
title = {Adaptive document image binarization},
journal = {Pattern Recognition},
volume = {33},
number = {2},
pages = {225-236},
year = {2000},
issn = {0031-3203},
doi = {https://doi.org/10.1016/S0031-3203(99)00055-2},
url = {https://www.sciencedirect.com/science/article/pii/S0031320399000552},
author = {J. Sauvola and M. Pietikäinen},
keywords = {Adaptive binarization, Soft decision, Document segmentation, Document analysis, Document understanding},
abstract = {A new method is presented for adaptive document image binarization, where the page is considered as a collection of subcomponents such as text, background and picture. The problems caused by noise, illumination and many source type-related degradations are addressed. Two new algorithms are applied to determine a local threshold for each pixel. The performance evaluation of the algorithm utilizes test images with ground-truth, evaluation metrics for binarization of textual and synthetic images, and a weight-based ranking procedure for the final result presentation. The proposed algorithms were tested with images including different types of document components and degradations. The results were compared with a number of known techniques in the literature. The benchmarking results show that the method adapts and performs well in each case qualitatively and quantitatively.}
}

@InProceedings{Tombre,
author="Tombre, Karl
and Tabbone, Salvatore
and P{\'e}lissier, Lo{\"i}c
and Lamiroy, Bart
and Dosch, Philippe",
editor="Lopresti, Daniel
and Hu, Jianying
and Kashi, Ramanujan",
title="Text/Graphics Separation Revisited",
booktitle="Document Analysis Systems V",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="200--211",
abstract="Text/graphics separation aims at segmenting the document into two layers: a layer assumed to contain text and a layer containing graphical objects. In this paper, we present a consolidation of a method proposed by Fletcher and Kasturi, with a number of improvements to make it more suitable for graphics-rich documents. We discuss the right choice of thresholds for this method, and their stability. We also propose a post-processing step for retrieving text components touching the graphics, through local segmentation of the distance skeleton.",
isbn="978-3-540-45869-2"
}
@book{Gonzalez,
author = {Gonzalez, Rafael and Faisal, Zahraa},
year = {2019},
month = {06},
pages = {},
title = {Digital Image Processing Second Edition}
}
@article{Kukich,
author = {Kukich, Karen},
title = {Techniques for automatically correcting words in text},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/146370.146380},
doi = {10.1145/146370.146380},
abstract = {Research aimed at correcting words in text has focused on three progressively more difficult problems:(1) nonword error detection; (2) isolated-word error correction; and (3) context-dependent work correction. In response to the first problem, efficient pattern-matching and n-gram analysis techniques have been developed for detecting strings that do not appear in a given word list. In response to the second problem, a variety of general and application-specific spelling correction techniques have been developed. Some of them were based on detailed studies of spelling error patterns. In response to the third problem, a few experiments using natural-language-processing tools or statistical-language models have been carried out. This article surveys documented findings on spelling error patterns, provides descriptions of various nonword detection and isolated-word error correction techniques, reviews the state of the art of context-dependent word correction techniques, and discusses research issues related to all three areas of automatic error correction in text.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {377–439},
numpages = {63},
keywords = {n-gram analysis, Optical Character Recognition (OCR), context-dependent spelling correction, grammar checking, natural-language-processing models, neural net classifiers, spell checking, spelling error detection, spelling error patterns, statistical-language models, word recognition and correction}
}
@article{Taghva,
author = {Taghva, Kazem and Stofsky, Eric},
year = {2001},
month = {03},
pages = {125-137},
title = {OCRSpell: An interactive spelling correction system for OCR errors in text},
volume = {3},
journal = {IJDAR},
doi = {10.1007/PL00013558}
}

@misc{memon2020handwrittenopticalcharacterrecognition,
      title={Handwritten Optical Character Recognition (OCR): A Comprehensive Systematic Literature Review (SLR)}, 
      author={Jamshed Memon and Maira Sami and Rizwan Ahmed Khan},
      year={2020},
      eprint={2001.00139},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2001.00139}, 
}

@misc{du2020ppocrpracticalultralightweight,
      title={PP-OCR: A Practical Ultra Lightweight OCR System}, 
      author={Yuning Du and Chenxia Li and Ruoyu Guo and Xiaoting Yin and Weiwei Liu and Jun Zhou and Yifan Bai and Zilin Yu and Yehua Yang and Qingqing Dang and Haoshuang Wang},
      year={2020},
      eprint={2009.09941},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2009.09941}, 
}
@misc{baek2019characterregionawarenesstext,
      title={Character Region Awareness for Text Detection}, 
      author={Youngmin Baek and Bado Lee and Dongyoon Han and Sangdoo Yun and Hwalsuk Lee},
      year={2019},
      eprint={1904.01941},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1904.01941}, 
}
@article{Binmakhashen,
author = {Binmakhashen, Galal and Mahmoud, Sabri},
year = {2019},
month = {10},
pages = {1-36},
title = {Document Layout Analysis: A Comprehensive Survey},
volume = {52},
journal = {ACM Computing Surveys},
doi = {10.1145/3355610}
}
@Inbook{Cohn1997,
author="Cohn, Anthony G.
and Bennett, Brandon
and Gooday, John
and Gotts, Nicholas M.",
editor="Stock, Oliviero",
title="Representing and Reasoning with Qualitative Spatial Relations About Regions",
bookTitle="Spatial and Temporal Reasoning",
year="1997",
publisher="Springer Netherlands",
address="Dordrecht",
pages="97--134",
abstract="Qualitative Reasoning (QR) has now become a mature subfield of AI as its tenth annual international workshop, several books (e.g. (Weld and de Kleer, 1990; Faltings and Struss, 1992)) and a wealth of conference and journal publications testify. QR tries to make explicit our everyday commonsense knowledge about the physical world and also the underlying abstractions used by scientists and engineers when they create models. Given this kind of knowledge and appropriate reasoning methods, a computer could make predictions and diagnoses and explain the behavior of physical systems in a qualitative manner, even when a precise quantitative description is not available or is computationally intractable. Note that a representation is not normally deemed to be qualitative by the QR community simply because it is symbolic and utilizes discrete quantity spaces but because the distinctions made in these discretizations are relevant to high-level descriptions of the system or behavior being modeled.",
isbn="978-0-585-28322-7",
doi="10.1007/978-0-585-28322-7_4",
url="https://doi.org/10.1007/978-0-585-28322-7_4"
}

@article{LeeRyu,
author = {Lee, Seong-Whan and Ryu, Dae-Seok},
title = {Parameter-Free Geometric Document Layout Analysis},
year = {2001},
issue_date = {November 2001},
publisher = {IEEE Computer Society},
address = {USA},
volume = {23},
number = {11},
issn = {0162-8828},
url = {https://doi.org/10.1109/34.969115},
doi = {10.1109/34.969115},
abstract = {Automatic transformation of paper documents into electronic documents requires geometric document layout analysis at the first stage. However, variations in character font sizes, text line spacing, and document layout structures have made it difficult to design a general-purpose document layout analysis algorithm for many years. The use of some parameters has therefore been unavoidable in previous methods. In this paper, we propose a parameter-free method for segmenting the document images into maximal homogeneous regions and identifying them as texts, images, tables, and ruling lines. A pyramidal quadtree structure is constructed for multiscale analysis and a periodicity measure is suggested to find a periodical attribute of text regions for page segmentation. To obtain robust page segmentation results, a confirmation procedure using texture analysis is applied to only ambiguous regions. Based on the proposed periodicity measure, multiscale analysis, and confirmation procedure, we could develop a robust method for geometric document layout analysis independent of character font sizes, text line spacing, and document layout structures. The proposed method was experimented with the document database from the University of Washington and the MediaTeam Document Database. The results of these tests have shown that the proposed method provides more accurate results than the previous ones.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = nov,
pages = {1240–1256},
numpages = {17},
keywords = {Geometric document layout analysis, multiscale analysis, page segmentation., parameter-free method, periodicity estimation}
}

@article{Simon,
author = {Simon, Anik\'{o} and Pret, Jean-Christophe and Johnson, A. Peter},
title = {A Fast Algorithm for Bottom-Up Document Layout Analysis},
year = {1997},
issue_date = {March 1997},
publisher = {IEEE Computer Society},
address = {USA},
volume = {19},
number = {3},
issn = {0162-8828},
url = {https://doi.org/10.1109/34.584106},
doi = {10.1109/34.584106},
abstract = {This paper describes a new bottom-up method for document layout analysis. The algorithm was implemented in the CLiDE (Chemical Literature Data Extraction) system (http://chem.leeds.ac.uk/ICAMS/CLiDE.html), but the method described here is suitable for a broader range of documents. It is based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure. The method has all the major advantages of bottom-up systems: independence from different text spacing and independence from different block alignments. The algorithms computational complexity is reduced to linear by using heuristics and path-compression.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = mar,
pages = {273–277},
numpages = {5},
keywords = {spanning tree, physical page layout, chemical documents., bottom-up layout analysis, Kruskal's algorithm, Document analysis}
}
@inproceedings{Dengel1989ANASTASILAH,
  title={ANASTASIL: A Hybrid Knowledge-Based System for Document Layout Analysis},
  author={Andreas R. Dengel and Gerhard Barth},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={1989},
  url={https://api.semanticscholar.org/CorpusID:7461436}
}

@misc{chen2017convolutionalneuralnetworkspage,
      title={Convolutional Neural Networks for Page Segmentation of Historical Document Images}, 
      author={Kai Chen and Mathias Seuret},
      year={2017},
      eprint={1704.01474},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.01474}, 
}
@inproceedings{Pfitzmann_2022, series={KDD ’22},
   title={DocLayNet: A Large Human-Annotated Dataset for Document-Layout Segmentation},
   url={http://dx.doi.org/10.1145/3534678.3539043},
   DOI={10.1145/3534678.3539043},
   booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S. and Staar, Peter},
   year={2022},
   month=aug, pages={3743–3751},
   collection={KDD ’22} }

@ARTICLE{Nagy,
  author={Nagy, G. and Seth, S. and Viswanathan, M.},
  journal={Computer}, 
  title={A prototype document image analysis system for technical journals}, 
  year={1992},
  volume={25},
  number={7},
  pages={10-22},
  keywords={Prototypes;Text analysis;Image analysis;Optical character recognition software;Image converters;Humans;Image storage;Character recognition;Image processing;Tree data structures},
  doi={10.1109/2.144436}}

  @INPROCEEDINGS{Kucer,
  author={Kucer, Michal and Oyen, Diane and Castorena, Juan and Wu, Jian},
  booktitle={2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={DeepPatent: Large scale patent drawing recognition and retrieval}, 
  year={2022},
  volume={},
  number={},
  pages={557-566},
  keywords={Deep learning;Training;Patents;Computer vision;Computational modeling;Image retrieval;Benchmark testing;Datasets;Evaluation and Comparison of Vision Algorithms Image/Video Indexing and Retrieval},
  doi={10.1109/WACV51458.2022.00063}}

@misc{futrelle1995efficientanalysiscomplexdiagrams,
      title={Efficient Analysis of Complex Diagrams using Constraint-Based Parsing}, 
      author={Robert P. Futrelle and Nikos Nikolakis},
      year={1995},
      eprint={cmp-lg/9505015},
      archivePrefix={arXiv},
      primaryClass={cmp-lg},
      url={https://arxiv.org/abs/cmp-lg/9505015}, 
}

@article{DERUYVER2009876,
title = {Qualitative spatial relationships for image interpretation by using a conceptual graph},
journal = {Image and Vision Computing},
volume = {27},
number = {7},
pages = {876-886},
year = {2009},
note = {7th IAPR-TC15 Workshop on Graph-based Representations (GbR 2007)},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2008.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0262885608002138},
author = {Aline Deruyver and Yann Hodé},
keywords = {Image interpretation, Spatial relationships, Conceptual graph, Arc-consistency analysis},
abstract = {In this paper, a new way to express complex spatial relations is proposed in order to integrate them in a Constraint Satisfaction Problem with bilevel constraints (CSPBC). The two levels of constraint were introduced to deal with the non bijective matching between segmented regions of an image and the nodes of a conceptual graph describing the semantic content of the image. This new system of spatial relations allows to build conceptual graphs describing more precisely the spatial relations between subparts of a composite object that we look for in an image. For example, it allows to express complex spatial relations such as “is surrounded by”. This approach can be applied to image interpretation and some examples on real images are presented.}
}
@book{Pachl,
author = {Pachl, Jörn},
year = {2021},
month = {01},
pages = {},
title = {Systemtechnik des Schienenverkehrs: Bahnbetrieb planen, steuern und sichern},
isbn = {978-3-658-31164-3},
doi = {10.1007/978-3-658-31165-0}
}

@misc{Poppler2024,
  author       = {{Poppler Development Team}},
  title        = {Poppler PDF rendering library},
  year         = {2024},
  howpublished = {\url{https://poppler.freedesktop.org/}},
  note         = {Accessed: 2024-05-20}
}

@misc{Belval2024,
  author       = {Belval, Edouard},
  title        = {pdf2image: A python wrapper for pdftoppm and pdftocairo},
  year         = {2024},
  howpublished = {\url{https://github.com/Belval/pdf2image}},
  note         = {GitHub repository. Accessed: 2024-05-20}
}

@misc{Shinyama2022,
  author       = {Shinyama, Yusuke},
  title        = {PDFMiner: Python PDF Parser},
  year         = {2022},
  howpublished = {\url{https://github.com/pdfminer/pdfminer.six}},
  note         = {Version 20221105. Accessed: 2024-05-20}
}
@misc{UltralyticsOBB,
  author       = {{Ultralytics}},
  title        = {YOLOv8 Oriented Bounding Boxes (OBB)},
  year         = {2024},
  howpublished = {\url{https://docs.ultralytics.com/tasks/obb/}},
  note         = {Accessed: 2024-05-20}
}

@INPROCEEDINGS{10204762,
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors}, 
  year={2023},
  volume={},
  number={},
  pages={7464-7475},
  keywords={Training;Computer vision;Source coding;Object detection;Detectors;Computer architecture;Real-time systems;Recognition: Categorization;detection;retrieval},
  doi={10.1109/CVPR52729.2023.00721}}
@article{Brunelli2009,
author = {Brunelli, Roberto},
year = {2008},
month = {09},
pages = {},
title = {Template Matching Techniques in Computer Vision}
}

@misc{carion2020endtoendobjectdetectiontransformers,
      title={End-to-End Object Detection with Transformers}, 
      author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
      year={2020},
      eprint={2005.12872},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2005.12872}, 
}
@article{Otsu1979gxi,
    author = "Otsu, Nobuyuki",
    title = "{A Threshold Selection Method from Gray-Level Histograms}",
    doi = "10.1109/tsmc.1979.4310076",
    journal = "IEEE Trans. Syst. Man Cybern.",
    volume = "9",
    number = "1",
    pages = "62--66",
    year = "1979"
}
@misc{huang2022layoutlmv3pretrainingdocumentai,
      title={LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking}, 
      author={Yupan Huang and Tengchao Lv and Lei Cui and Yutong Lu and Furu Wei},
      year={2022},
      eprint={2204.08387},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.08387}, 
}

@misc{kim2022ocrfreedocumentunderstandingtransformer,
      title={OCR-free Document Understanding Transformer}, 
      author={Geewook Kim and Teakgyu Hong and Moonbin Yim and Jeongyeon Nam and Jinyoung Park and Jinyeong Yim and Wonseok Hwang and Sangdoo Yun and Dongyoon Han and Seunghyun Park},
      year={2022},
      eprint={2111.15664},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.15664}, 
}
@misc{li2022trocrtransformerbasedopticalcharacter,
      title={TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models}, 
      author={Minghao Li and Tengchao Lv and Jingye Chen and Lei Cui and Yijuan Lu and Dinei Florencio and Cha Zhang and Zhoujun Li and Furu Wei},
      year={2022},
      eprint={2109.10282},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.10282}, 
}
@misc{StreamlitSecurity,
  author       = {{Streamlit Inc.}},
  title        = {Streamlit Security Best Practices and Deployment},
  year         = {2024},
  howpublished = {\url{https://docs.streamlit.io/deploy}},
  note         = {Accessed: 2024-05-20}
}
@misc{SQLiteVsPostgres,
  author       = {{SQLite Development Team}},
  title        = {Appropriate Uses For SQLite},
  year         = {2024},
  howpublished = {\url{https://sqlite.org/whentouse.html}},
  note         = {Accessed: 2024-05-20}
}

@misc{openpyxl,
  author = {{openpyxl contributors}},
  title = {openpyxl: A Python library to read/write Excel 2010 xlsx/xlsm files},
  year = {2024},
  url = {https://openpyxl.readthedocs.io}
}


@misc{pyqt5,
  author = {Riverbank Computing},
  title = {PyQt5 Reference Guide},
  year = {2024},
  url = {https://www.riverbankcomputing.com/static/Docs/PyQt5/}
}

@manual{postgresql_docs,
  title = {PostgreSQL 15 Documentation},
  organization = {The PostgreSQL Global Development Group},
  year = {2024},
  url = {https://www.postgresql.org/docs/15/}
}

@misc{cvat,
  author = {{Intel Corporation}},
  title = {CVAT: Computer Vision Annotation Tool},
  year = {2024},
  url = {https://github.com/opencv/cvat}
}

@misc{easyocr,
  author = {JaidedAI},
  title = {EasyOCR: Ready-to-use OCR with 80+ supported languages},
  year = {2024},
  url = {https://github.com/JaidedAI/EasyOCR}
}

@article{levenshtein1966,
  author = {Levenshtein, Vladimir I.},
  title = {Binary codes capable of correcting deletions, insertions, and reversals},
  journal = {Soviet Physics Doklady},
  volume = {10},
  number = {8},
  pages = {707--710},
  year = {1966}
}
@article{stonebraker2019case,
  title = {What goes around comes around... and around...},
  author = {Stonebraker, Michael and Hellerstein, Joseph M.},
  journal = {Communications of the ACM},
  volume = {61},
  number = {2},
  pages = {35--43},
  year = {2018}
}

@book{hopcroft2001automata,
  title = {Introduction to Automata Theory, Languages, and Computation},
  author = {Hopcroft, John E. and Motwani, Rajeev and Ullman, Jeffrey D.},
  edition = {2nd},
  year = {2001},
  publisher = {Addison-Wesley}
}

@misc{yaml_spec,
  title = {YAML Ain't Markup Language (YAML) Version 1.2},
  author = {{YAML Language Development Team}},
  year = {2021},
  url = {https://yaml.org/spec/1.2/spec.html}
}

@techreport{json_rfc,
  title = {The JavaScript Object Notation (JSON) Data Interchange Format},
  author = {Bray, T.},
  type = {RFC},
  number = {8259},
  year = {2017},
  institution = {IETF},
  url = {https://tools.ietf.org/html/rfc8259}
}
@ARTICL{LeCun1998_GradientBasedLearning,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}

@article{Krizhevsky2012_AlexNet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet classification with deep convolutional neural networks},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {60},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3065386},
doi = {10.1145/3065386},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
journal = {Commun. ACM},
month = may,
pages = {84–90},
numpages = {7}
}  

@ARTICLE{Zou2019_ObjectDetectionSurvey,
  author={Zou, Zhengxia and Chen, Keyan and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
  journal={Proceedings of the IEEE}, 
  title={Object Detection in 20 Years: A Survey}, 
  year={2023},
  volume={111},
  number={3},
  pages={257-276},
  keywords={Object detection;Detectors;Computer vision;Feature extraction;Deep learning;Convolutional neural networks;Computer vision;convolutional neural networks (CNNs);deep learning;object detection;technical evolution},
  doi={10.1109/JPROC.2023.3238524}}

@article{Liu2020_DeepLearningDetectionSurvey,
author = {Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietik\"{a}inen, Matti},
title = {Deep Learning for Generic Object Detection: A Survey},
year = {2020},
issue_date = {Feb 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {128},
number = {2},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-019-01247-4},
doi = {10.1007/s11263-019-01247-4},
abstract = {Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.},
journal = {Int. J. Comput. Vision},
month = feb,
pages = {261–318},
numpages = {58},
keywords = {Object detection, Deep learning, Convolutional neural networks, Object recognition}
}
@inproceedings{Ahmed2011,
author = {Ahmed, Sheraz and Liwicki, Marcus and Weber, Markus and Dengel, Andreas},
year = {2012},
month = {03},
pages = {339-343},
title = {Automatic Room Detection and Room Labeling from Architectural Floor Plans},
isbn = {9780769546612},
journal = {Proceedings - 10th IAPR International Workshop on Document Analysis Systems, DAS 2012},
doi = {10.1109/DAS.2012.22}
}

@article{Rahul2019,
  title={Automatic Information Extraction from Piping and Instrumentation Diagrams},
  author={Rohit Rahul and Shubham Paliwal and Monika Sharma and Lovekesh Vig},
  journal={ArXiv},
  year={2019},
  volume={abs/1901.11383},
  url={https://api.semanticscholar.org/CorpusID:59523595}
}
@article{Lowe2004,
  title={Distinctive Image Features from Scale-Invariant Keypoints},
  author={David G. Lowe},
  journal={International Journal of Computer Vision},
  year={2004},
  volume={60},
  pages={91-110},
  url={https://api.semanticscholar.org/CorpusID:174065}
}

@inproceedings{Bay2008,
author = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
year = {2006},
month = {07},
pages = {404-417},
title = {SURF: Speeded up robust features},
volume = {3951},
isbn = {978-3-540-33832-1},
journal = {Computer Vision-ECCV 2006},
doi = {10.1007/11744023_32}
}
@INPROCEEDINGS{Dalal2005,
  author={Dalal, N. and Triggs, B.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Histograms of oriented gradients for human detection}, 
  year={2005},
  volume={1},
  number={},
  pages={886-893 vol. 1},
  keywords={Histograms;Humans;Robustness;Object recognition;Support vector machines;Object detection;Testing;Image edge detection;High performance computing;Image databases},
  doi={10.1109/CVPR.2005.177}}

@InProceedings{Lin2017_FPN,
author = {Lin, Tsung-Yi and Dollar, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
title = {Feature Pyramid Networks for Object Detection},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {06},
year = {2017}
}
@misc{Lin2014_COCO,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1405.0312}, 
}
@article{Everingham2010_PascalVOC,
author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher and Winn, John and Zisserman, Andrew},
year = {2010},
month = {06},
pages = {303-338},
title = {The Pascal Visual Object Classes (VOC) challenge},
volume = {88},
journal = {International Journal of Computer Vision},
doi = {10.1007/s11263-009-0275-4}
}

@article{Moreno2019,
title = "New trends on digitisation of complex engineering drawings",
abstract = "Engineering drawings are commonly used across different industries such as oil and gas, mechanical engineering and others. Digitising these drawings is becoming increasingly important. This is mainly due to the legacy of drawings and documents that may provide rich source of information for industries. Analysing these drawings often requires applying a set of digital image processing methods to detect and classify symbols and other components. Despite the recent significant advances in image processing, and in particular in deep neural networks, automatic analysis and processing of these engineering drawings is still far from being complete. This paper presents a general framework for complex engineering drawing digitisation. A thorough and critical review of relevant literature, methods and algorithms in machine learning and machine vision is presented. Real-life industrial scenario on how to contextualise the digitised information from specific type of these drawings, namely piping and instrumentation diagrams, is discussed in details. A discussion of how new trends on machine vision such as deep learning could be applied to this domain is presented with conclusions and suggestions for future research directions.",
author = "Moreno-garc{\'i}a, \{Carlos Francisco\} and Eyad Elyan and Chrisina Jayne",
year = "2019",
month = jun,
day = "30",
doi = "10.1007/s00521-018-3583-1",
language = "English",
volume = "31",
pages = "1695--1712",
journal = "Neural Computing and Applications",
issn = "0941-0643",
publisher = "Springer London",
number = "6",
}
@article{Cortes1995_SVM,
  title={Support-Vector Networks},
  author={Corinna Cortes and Vladimir Naumovich Vapnik},
  journal={Machine Learning},
  year={1995},
  volume={20},
  pages={273-297},
  url={https://api.semanticscholar.org/CorpusID:52874011}
}
@article{Rumelhart1986_Backpropagation,
  title={Learning representations by back-propagating errors},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal={Nature},
  year={1986},
  volume={323},
  pages={533-536},
  url={https://api.semanticscholar.org/CorpusID:205001834}
}
@article{Robbins1951_SGD,
  title={A Stochastic Approximation Method},
  author={Herbert E. Robbins},
  journal={Annals of Mathematical Statistics},
  year={1951},
  volume={22},
  pages={400-407},
  url={https://api.semanticscholar.org/CorpusID:16945044}
}

@misc{Kingma2015_Adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@article{Goodfellow2016_DeepLearning,
author = {Heaton, Jeffrey},
year = {2017},
month = {10},
pages = {},
title = {Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning: The MIT Press, 2016, 800 pp, ISBN: 0262035618},
volume = {19},
journal = {Genetic Programming and Evolvable Machines},
doi = {10.1007/s10710-017-9314-z}
}

@misc{Bochkovskiy2020_YOLOv4,
      title={YOLOv4: Optimal Speed and Accuracy of Object Detection}, 
      author={Alexey Bochkovskiy and Chien-Yao Wang and Hong-Yuan Mark Liao},
      year={2020},
      eprint={2004.10934},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2004.10934}, 
}
@inproceedings{Deng2009_ImageNet,
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Li, Fei-Fei},
year = {2009},
month = {06},
pages = {248-255},
title = {ImageNet: a Large-Scale Hierarchical Image Database},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206848}
}

@misc{Zeiler2014_Visualizing,
      title={Visualizing and Understanding Convolutional Networks}, 
      author={Matthew D Zeiler and Rob Fergus},
      year={2013},
      eprint={1311.2901},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1311.2901}, 
}

@INPROCEEDINGS{Girshick2014_RCNN,
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation}, 
  year={2014},
  volume={},
  number={},
  pages={580-587},
  keywords={Proposals;Feature extraction;Training;Visualization;Object detection;Vectors;Support vector machines},
  doi={10.1109/CVPR.2014.81}
  }


@INPROCEEDINGS{Rezatofighi2019_GIoU,
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression}, 
  year={2019},
  volume={},
  number={},
  pages={658-666},
  keywords={Measurement;Computer vision;Art;Three-dimensional displays;Shape;Object detection;Benchmark testing;Loss measurement;Pattern recognition;Standards;Recognition: Detection;Categorization;Retrieval;Deep Learning},
  doi={10.1109/CVPR.2019.00075}}
@INPROCEEDINGS{Xia2018_DOTA,
  author={Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={DOTA: A Large-Scale Dataset for Object Detection in Aerial Images}, 
  year={2018},
  volume={},
  number={},
  pages={3974-3983},
  keywords={Object detection;Earth;Sports;Computer vision;Sensors;Marine vehicles;Image sensors},
  doi={10.1109/CVPR.2018.00418}}

@INPROCEEDINGS{Ding2019_LearningRoI,
  author={Ding, Jian and Xue, Nan and Long, Yang and Xia, Gui-Song and Lu, Qikai},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning RoI Transformer for Oriented Object Detection in Aerial Images}, 
  year={2019},
  volume={},
  number={},
  pages={2844-2853},
  keywords={Location awareness;Computer vision;Annotations;Computational modeling;Object detection;Transformer cores;Transformers;Recognition: Detection;Categorization;Retrieval;Deep Learning;Vision Applications and Systems},
  doi={10.1109/CVPR.2019.00296}}

@article{Cheng2016_SurveyRemoteSensing,
title = {A survey on object detection in optical remote sensing images},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {117},
pages = {11-28},
year = {2016},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2016.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616300144},
author = {Gong Cheng and Junwei Han},
keywords = {Object detection, Optical remote sensing images, Template matching, Object-based image analysis (OBIA), Machine learning, Deep learning, Weakly supervised learning},
abstract = {Object detection in optical remote sensing images, being a fundamental but challenging problem in the field of aerial and satellite image analysis, plays an important role for a wide range of applications and is receiving significant attention in recent years. While enormous methods exist, a deep review of the literature concerning generic object detection is still lacking. This paper aims to provide a review of the recent progress in this field. Different from several previously published surveys that focus on a specific object class such as building and road, we concentrate on more generic object categories including, but are not limited to, road, building, tree, vehicle, ship, airport, urban-area. Covering about 270 publications we survey (1) template matching-based object detection methods, (2) knowledge-based object detection methods, (3) object-based image analysis (OBIA)-based object detection methods, (4) machine learning-based object detection methods, and (5) five publicly available datasets and three standard evaluation metrics. We also discuss the challenges of current studies and propose two promising research directions, namely deep learning-based feature representation and weakly supervised learning-based geospatial object detection. It is our hope that this survey will be beneficial for the researchers to have better understanding of this research field.}
}

@ARTICLE{Dollar2012_PedestrianDetection,
  author={Dollar, Piotr and Wojek, Christian and Schiele, Bernt and Perona, Pietro},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Pedestrian Detection: An Evaluation of the State of the Art}, 
  year={2012},
  volume={34},
  number={4},
  pages={743-761},
  keywords={Detectors;Pixel;Cameras;Training;Testing;Heating;Labeling;Pedestrian detection;object detection;benchmark;evaluation;data set;Caltech Pedestrian data set.},
  doi={10.1109/TPAMI.2011.155}}
@INPROCEEDINGS{Geiger2012_KITTI,
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
  year={2012},
  volume={},
  number={},
  pages={3354-3361},
  keywords={Benchmark testing;Cameras;Optical imaging;Visualization;Optical sensors;Measurement},
  doi={10.1109/CVPR.2012.6248074}}
@article{Bodla2017_SoftNMS,
author = {Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and Davis, Larry},
year = {2017},
month = {04},
pages = {},
title = {Improving Object Detection With One Line of Code},
doi = {10.48550/arXiv.1704.04503}
}

@misc{Liu2019_AdaptiveNMS,
      title={Adaptive NMS: Refining Pedestrian Detection in a Crowd}, 
      author={Songtao Liu and Di Huang and Yunhong Wang},
      year={2019},
      eprint={1904.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1904.03629}, 
}

% 1. EAST Text Detector (foundational OBB work)
@INPROCEEDINGS{Zhou2017EastAE,
  author={Zhou, Xinyu and Yao, Cong and Wen, He and Wang, Yuzhi and Zhou, Shuchang and He, Weiran and Liang, Jiajun},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={EAST: An Efficient and Accurate Scene Text Detector}, 
  year={2017},
  volume={},
  number={},
  pages={2642-2651},
  keywords={Text detection;Feature extraction;Pipelines;Training;Decoding;Geometry;Neural networks},
  doi={10.1109/CVPR.2017.283},
  url={https://doi.org/10.1109/CVPR.2017.283}
}

% 2. Arbitrary-Oriented Scene Text Detection
@INPROCEEDINGS{Ma2018ArbitraryOrientedST,
  author={Ma, Jianqi and Shao, Weiyuan and Ye, Hao and Wang, Li and Wang, Hong and Zheng, Yingbin and Xue, Xiangyang},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Arbitrary-Oriented Scene Text Detection via Rotation Proposals}, 
  year={2018},
  volume={},
  number={},
  pages={3892-3900},
  keywords={Text detection;Proposals;Feature extraction;Training;Task analysis;Neural networks;Detectors},
  doi={10.1109/CVPR.2018.00410},
  url={https://doi.org/10.1109/CVPR.2018.00410}
}

% 3. R3Det with KLD Loss
@misc{Yang2021RSDETR,
  title={R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object}, 
  author={Xue Yang and Junchi Yan and Qi Ming and Wentao Wang and Xiaopeng Zhang and Qi Tian},
  year={2021},
  eprint={1908.05612},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1908.05612},
  doi={10.48550/arXiv.1908.05612}
}

% 4. Oriented R-CNN
@INPROCEEDINGS{Xie2021OrientedRD,
  author={Xie, Xingxing and Cheng, Gong and Wang, Jiabao and Yao, Xiwen and Han, Junwei},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Oriented R-CNN for Object Detection}, 
  year={2021},
  volume={},
  number={},
  pages={3500-3509},
  keywords={Training;Detectors;Object detection;Proposals;Predictive models;Atmospheric modeling;Computer vision},
  doi={10.1109/ICCV48922.2021.00350},
  url={https://doi.org/10.1109/ICCV48922.2021.00350}
}

% 5. Gaussian Wasserstein Distance Loss
@INPROCEEDINGS{Yang2021GWDRotated,
  author={Yang, Xue and Yan, Junchi and Feng, Ziming and He, Tao},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss}, 
  year={2021},
  volume={},
  number={},
  pages={4602-4611},
  keywords={Training;Optimization;Detectors;Proposals;Object detection;Predictive models;Computer vision},
  doi={10.1109/ICCV48922.2021.00457},
  url={https://doi.org/10.1109/ICCV48922.2021.00457}
}

% 6. CSPNet Backbone
@INPROCEEDINGS{Wang2020_CSPNet,
  author={Wang, Chien-Yao and Liao, Hong-Yuan Mark and Wu, Yueh-Hua and Chen, Ping-Yang and Hsieh, Jun-Wei and Yeh, I-Hau},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={CSPNet: A New Backbone That Can Enhance Learning Capability of CNN}, 
  year={2020},
  volume={},
  number={},
  pages={1571-1580},
  keywords={Training;Computer vision;Computer architecture;Computational modeling;Neural networks;Computational efficiency;Task analysis},
  doi={10.1109/CVPRW50498.2020.00203},
  url={https://doi.org/10.1109/CVPRW50498.2020.00203}
}

% 7. Path Aggregation Network
@INPROCEEDINGS{Liu2018_PANet,
  author={Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Path Aggregation Network for Instance Segmentation}, 
  year={2018},
  volume={},
  number={},
  pages={8759-8768},
  keywords={Adaptation models;Proposals;Task analysis;Computer architecture;Feature extraction;Semantics;Image segmentation},
  doi={10.1109/CVPR.2018.00913},
  url={https://doi.org/10.1109/CVPR.2018.00913}
}

% 8. YOLOX Decoupled Head
@misc{Ge2021_YOLOX,
  title={YOLOX: Exceeding YOLO Series in 2021}, 
  author={Zheng Ge and Songtao Liu and Feng Wang and Zeming Li and Jian Sun},
  year={2021},
  eprint={2107.08430},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2107.08430},
  doi={10.48550/arXiv.2107.08430}
}

% 9. Focal Loss (RetinaNet)
@INPROCEEDINGS{Lin2017_FocalLoss,
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Focal Loss for Dense Object Detection}, 
  year={2017},
  volume={},
  number={},
  pages={2999-3007},
  keywords={Detectors;Training;Object detection;Proposals;Semantics;Conferences;Neural networks},
  doi={10.1109/ICCV.2017.324},
  url={https://doi.org/10.1109/ICCV.2017.324}
}

% 10. EfficientNet Model Scaling
@INPROCEEDINGS{Tan2019_EfficientNet,
  author={Tan, Mingxing and Le, Quoc V.},
  booktitle={2019 International Conference on Machine Learning (ICML)}, 
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
  year={2019},
  volume={97},
  pages={6105-6114},
  publisher={PMLR},
  url={http://proceedings.mlr.press/v97/tan19a.html},
  note={ICML 2019}
}

@ARTICLE{Zhao2023ABFL,
  author={Zhao, Zifei and Li, Shengyang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented Object Detection in Aerial Images}, 
  year={2024},
  volume={62},
  number={},
  pages={1-11},
  keywords={Detectors;Object detection;Task analysis;Vectors;Feature extraction;Encoding;Training;Aerial images;anchor-free detector;angular boundary discontinuity (ABD);angular boundary discontinuity free loss (ABFL);arbitrary oriented object detection (AOOD);von Mises distribution},
  doi={10.1109/TGRS.2024.3368630}}


@INPROCEEDINGS{Tian2019FCOS,
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={FCOS: Fully Convolutional One-Stage Object Detection}, 
  year={2019},
  volume={},
  number={},
  pages={9626-9635},
  keywords={Detectors;Training;Task analysis;Object detection;Semantics;Feature extraction;Head},
  doi={10.1109/ICCV.2019.00972}}

@misc{Li2020GeneralizedFocal,
      title={Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection}, 
      author={Xiang Li and Wenhai Wang and Lijun Wu and Shuo Chen and Xiaolin Hu and Jun Li and Jinhui Tang and Jian Yang},
      year={2020},
      eprint={2006.04388},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.04388}, 
}

@ARTICLE{Mori1999,
  author={Mori, S. and Suen, C.Y. and Yamamoto, K.},
  journal={Proceedings of the IEEE}, 
  title={Historical review of OCR research and development}, 
  year={1992},
  volume={80},
  number={7},
  pages={1029-1058},
  keywords={Optical character recognition software;Research and development;Pattern recognition;History;Character recognition;Magnetooptic recording;Expert systems;Neural networks;Optical computing;Feature extraction},
  doi={10.1109/5.156468}}

@misc{Shi2017_CRNN,
  title={An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition}, 
  author={Baoguang Shi and Xiang Bai and Cong Yao},
  year={2017},
  eprint={1507.05717},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1507.05717}
}

@article{Hochreiter1997_LSTM,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{Graves2006_CTC,
author = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
year = {2006},
month = {01},
pages = {369-376},
title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
volume = {2006},
journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
doi = {10.1145/1143844.1143891}
}

@misc{Vaswani2017_Attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{Jaderberg2015_STN,
      title={Spatial Transformer Networks}, 
      author={Max Jaderberg and Karen Simonyan and Andrew Zisserman and Koray Kavukcuoglu},
      year={2016},
      eprint={1506.02025},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1506.02025}, 
}

@article{Bertalmio2000_Inpainting,
author = {Bertalmio, Marcelo and Sapiro, Guillermo and Ballester, C.},
year = {2002},
month = {01},
pages = {},
title = {Image Inpainting},
journal = {Proceedings of SIGGRAPH},
doi = {10.1145/344779.344972}
}

@misc{Dosovitskiy2021_ViT,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}